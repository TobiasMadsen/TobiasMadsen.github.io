{
    "componentChunkName": "component---src-templates-blog-post-js",
    "path": "/2015/03/26/locally-weighted-logistic-regression/",
    "result": {"data":{"site":{"siteMetadata":{"title":"TobiasMadsen.com"}},"markdownRemark":{"id":"2bd4cf66-b30e-543e-8f5c-523b73064c5d","excerpt":"Given a male patient 45 years of age and a BMI of 27 how great is the risk of having diabetes? What is the relationship between the chance of wining an election…","html":"<p>Given a male patient 45 years of age and a BMI of 27 how great is the risk of having diabetes? What is the relationship between the chance of wining an election and the campaign budget? How does the probability of playing in NBA increase with height?\nA simple way to approach such problems is by looking at similar observations, for instance look at men at ages between 40-50 and a BMI 25-30 and use the frequency of diabetes in this group to infer the risk for our given patient.\nLogistic regression is a more sophisticated method. There we model the probability of having diabetes as a function of the covariates of the following form:</p>\n<div class=\"math math-display\"><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mi>log</mi><mo>⁡</mo><mfrac><mrow><mi>π</mi><mo stretchy=\"false\">(</mo><mi mathvariant=\"bold\">x</mi><mo stretchy=\"false\">)</mo></mrow><mrow><mn>1</mn><mo>−</mo><mi>π</mi><mo stretchy=\"false\">(</mo><mi mathvariant=\"bold\">x</mi><mo stretchy=\"false\">)</mo></mrow></mfrac><mo>=</mo><msub><mi>β</mi><mn>0</mn></msub><mo>+</mo><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>p</mi></munderover><msub><mi>β</mi><mi>i</mi></msub><msub><mi>x</mi><mi>i</mi></msub><mi mathvariant=\"normal\">.</mi></mrow><annotation encoding=\"application/x-tex\">\\log\\frac{\\pi(\\mathbf{x})}{1-\\pi(\\mathbf{x})} = \\beta_0 + \\sum_{i=1}^p \\beta_ix_i.</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:2.363em;vertical-align:-0.936em;\"></span><span class=\"mop\">lo<span style=\"margin-right:0.01389em;\">g</span></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.427em;\"><span style=\"top:-2.314em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\">1</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">π</span><span class=\"mopen\">(</span><span class=\"mord mathbf\">x</span><span class=\"mclose\">)</span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.677em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">π</span><span class=\"mopen\">(</span><span class=\"mord mathbf\">x</span><span class=\"mclose\">)</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.936em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.8888799999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.05278em;\">β</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.05278em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">0</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:2.9761740000000003em;vertical-align:-1.277669em;\"></span><span class=\"mop op-limits\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.6985050000000004em;\"><span style=\"top:-1.872331em;margin-left:0em;\"><span class=\"pstrut\" style=\"height:3.05em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">i</span><span class=\"mrel mtight\">=</span><span class=\"mord mtight\">1</span></span></span></span><span style=\"top:-3.050005em;\"><span class=\"pstrut\" style=\"height:3.05em;\"></span><span><span class=\"mop op-symbol large-op\">∑</span></span></span><span style=\"top:-4.347113em;margin-left:0em;\"><span class=\"pstrut\" style=\"height:3.05em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">p</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.277669em;\"><span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.05278em;\">β</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.05278em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord\">.</span></span></span></span></span></div>\n<p>In the heart of this equation we have a linear model; even if the predicted probability is not linear in the predictors, it is restricted to the logistic curve:</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 432px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/d52b76e546b3958a30c4da78ee92bd94/0e0c3/logistic_function-1.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 50%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAKCAYAAAC0VX7mAAAACXBIWXMAAAsTAAALEwEAmpwYAAAA1UlEQVQoz4WSyQqFMAxF+/8/6VJX4jxrHidwS6nDKwRNenuSJg1mZsMw2LqudhyH7fv+aWjO87RlWWwcx2jzPPteADhNkwOv63KxvrI0DrTrOuv73s8JSAL2HIgAIItDT8biQNu2/s2XkoWqqlykCt6MfelYuR7fgUVRWFmWMetbdf9uEYF1XXtmGpoLBGNo9OmpshtQ2bdtu/UFUQr76m8EEuAA12H0/JOgaRqvnBhibvBmgkWgxg+AfzZ4BulTIk5MTwlfsNQP6dhV/pMPPG2Lpp37PxolE64+EmQoAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"center\"\n        title=\"center\"\n        src=\"/static/d52b76e546b3958a30c4da78ee92bd94/0e0c3/logistic_function-1.png\"\n        srcset=\"/static/d52b76e546b3958a30c4da78ee92bd94/c26ae/logistic_function-1.png 158w,\n/static/d52b76e546b3958a30c4da78ee92bd94/6bdcf/logistic_function-1.png 315w,\n/static/d52b76e546b3958a30c4da78ee92bd94/0e0c3/logistic_function-1.png 432w\"\n        sizes=\"(max-width: 432px) 100vw, 432px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n  </a>\n    </span></p>\n<p>No method is perfect: Logistic regression makes some crude assumptions on the data, this might be good in the face of few datapoints, but too restrictive if we have a lot of data. On the other hand nearest neighbor methods, does not make many assumptions and can capture non-linear relationships between predictor and response, but might fail if there are not enough similar patients or if we are at the boundary of the data. The last point is critical: Say that the risk of diabetes increases with BMI, and we have a patient with very high BMI, most similar patients will tend to have a lower BMI, and we will have a tendency to underestimate the diabetes-risk.</p>\n<p>Locally weighted logistic regression tries to marry the two methods. The prediction in a point, <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>x</mi></mrow><annotation encoding=\"application/x-tex\">x</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord mathnormal\">x</span></span></span></span></span>, is based on a logistic regression model, but with a weighted dataset, that emphasizes datapoints near <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>x</mi></mrow><annotation encoding=\"application/x-tex\">x</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord mathnormal\">x</span></span></span></span></span>.</p>\n<h4>Fitting</h4>\n<p>Locally weighted logistic regression models can be fitted using <code class=\"language-text\">glm</code> just as usual logistic regression. We need to set the weights using the <code class=\"language-text\">weight</code> argument in <code class=\"language-text\">glm</code>. The documentation states that:</p>\n<blockquote>\nFor a binomial GLM prior weights are used to give the number of trials when the response is the proportion of successes.\n</blockquote>\n<p>The method does produce the correct estimates even if we provide non-integer weights, we will get a warning though and one should be cautious of scaling the weights correctly if you want confidence intervals(more below). To get rid of the of the warning use <code class=\"language-text\">family=quasibinomial('logit')</code> instead of <code class=\"language-text\">family=binomial('logit')</code>.</p>\n<p>We look at a dataset from the <em>National Healthh and Nutrition Examination Survey</em>.\nThe data can be found <a href=\"/assets/locally-weighted-logistic-regression/nhanes.dat\">here</a>.\nWe will try to estimate risk of being <code class=\"language-text\">obese</code> using <code class=\"language-text\">seated</code> the number of minutes of seated activity pr. week.\nNotice that <code class=\"language-text\">seated</code> is reported rather than measured thus taking only values that are multiples of 30 in the higher range.\nThis is less than ideal, but I went with this dataset anyway because it provides a good example of a non-monotone relation between predictor and response.</p>\n<div class=\"gatsby-highlight\" data-language=\"r\"><pre class=\"language-r\"><code class=\"language-r\">library<span class=\"token punctuation\">(</span>dplyr<span class=\"token punctuation\">)</span>\nnhanes <span class=\"token operator\">&lt;-</span> read.table<span class=\"token punctuation\">(</span><span class=\"token string\">'nhanes.dat'</span><span class=\"token punctuation\">,</span> na.strings<span class=\"token operator\">=</span><span class=\"token string\">\".\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">[</span><span class=\"token punctuation\">,</span>c<span class=\"token punctuation\">(</span><span class=\"token number\">20</span><span class=\"token punctuation\">,</span><span class=\"token number\">21</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span> <span class=\"token percent-operator operator\">%>%</span>\n  do<span class=\"token punctuation\">(</span>filter<span class=\"token punctuation\">(</span>.<span class=\"token punctuation\">,</span>complete.cases<span class=\"token punctuation\">(</span>.<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\nnames<span class=\"token punctuation\">(</span>nhanes<span class=\"token punctuation\">)</span> <span class=\"token operator\">&lt;-</span> c<span class=\"token punctuation\">(</span><span class=\"token string\">'seated'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'obese'</span><span class=\"token punctuation\">)</span></code></pre></div>\n<p>First we fit a simple logistic regression model</p>\n<div class=\"gatsby-highlight\" data-language=\"r\"><pre class=\"language-r\"><code class=\"language-r\">lrfit <span class=\"token operator\">&lt;-</span> glm<span class=\"token punctuation\">(</span>obese <span class=\"token operator\">~</span> seated<span class=\"token punctuation\">,</span> \n             data <span class=\"token operator\">=</span> nhanes<span class=\"token punctuation\">,</span> \n             family <span class=\"token operator\">=</span> binomial<span class=\"token punctuation\">(</span><span class=\"token string\">'logit'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># Obtain estimates</span>\nnewdata <span class=\"token operator\">=</span> data.frame<span class=\"token punctuation\">(</span> seated <span class=\"token operator\">=</span> seq<span class=\"token punctuation\">(</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span><span class=\"token number\">840</span><span class=\"token punctuation\">,</span><span class=\"token number\">5</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\npred <span class=\"token operator\">&lt;-</span> predict<span class=\"token punctuation\">(</span>lrfit<span class=\"token punctuation\">,</span> newdata<span class=\"token punctuation\">,</span> type<span class=\"token operator\">=</span><span class=\"token string\">'link'</span><span class=\"token punctuation\">,</span> se.fit <span class=\"token operator\">=</span> T<span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># Calculate confidence intervals</span>\nupr <span class=\"token operator\">&lt;-</span> lrfit<span class=\"token operator\">$</span>family<span class=\"token operator\">$</span>linkinv<span class=\"token punctuation\">(</span> pred<span class=\"token operator\">$</span>fit <span class=\"token operator\">+</span> <span class=\"token punctuation\">(</span><span class=\"token number\">1.96</span> <span class=\"token operator\">*</span> pred<span class=\"token operator\">$</span>se.fit<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">)</span>\nlwr <span class=\"token operator\">&lt;-</span> lrfit<span class=\"token operator\">$</span>family<span class=\"token operator\">$</span>linkinv<span class=\"token punctuation\">(</span> pred<span class=\"token operator\">$</span>fit <span class=\"token operator\">-</span> <span class=\"token punctuation\">(</span><span class=\"token number\">1.96</span> <span class=\"token operator\">*</span> pred<span class=\"token operator\">$</span>se.fit<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">)</span>\nfit <span class=\"token operator\">&lt;-</span> lrfit<span class=\"token operator\">$</span>family<span class=\"token operator\">$</span>linkinv<span class=\"token punctuation\">(</span> pred<span class=\"token operator\">$</span>fit <span class=\"token punctuation\">)</span>\n\nplot_df <span class=\"token operator\">&lt;-</span> data.frame<span class=\"token punctuation\">(</span> seated <span class=\"token operator\">=</span> seq<span class=\"token punctuation\">(</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span><span class=\"token number\">840</span><span class=\"token punctuation\">,</span><span class=\"token number\">5</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n                       p <span class=\"token operator\">=</span> fit<span class=\"token punctuation\">,</span> \n                       upr <span class=\"token operator\">=</span> upr<span class=\"token punctuation\">,</span> \n                       lwr <span class=\"token operator\">=</span> lwr<span class=\"token punctuation\">,</span>\n                       lambda <span class=\"token operator\">=</span> <span class=\"token number\">Inf</span> <span class=\"token punctuation\">)</span></code></pre></div>\n<p>We get the following estimates of the probability.</p>\n<div class=\"gatsby-highlight\" data-language=\"r\"><pre class=\"language-r\"><code class=\"language-r\">library<span class=\"token punctuation\">(</span>ggplot2<span class=\"token punctuation\">)</span>\nggplot<span class=\"token punctuation\">(</span>plot_df<span class=\"token punctuation\">,</span> aes<span class=\"token punctuation\">(</span>x <span class=\"token operator\">=</span> seated<span class=\"token punctuation\">,</span> y <span class=\"token operator\">=</span> p<span class=\"token punctuation\">,</span> ymin <span class=\"token operator\">=</span> lwr<span class=\"token punctuation\">,</span> ymax <span class=\"token operator\">=</span> upr<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">+</span> geom_line<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">+</span> geom_ribbon<span class=\"token punctuation\">(</span>alpha <span class=\"token operator\">=</span> <span class=\"token number\">0.4</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">+</span> theme_bw<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></code></pre></div>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 576px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/79b2744184a3ae5de4e4828bc2239a6e/533c1/simpleLogisticPlot-1.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 62.65822784810127%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAANCAYAAACpUE5eAAAACXBIWXMAAAsTAAALEwEAmpwYAAABUElEQVQ4y52SW6uCUBCF/f//JIxEg0hE8EGo6EKCL4Ih0Y16CKJ7qeuw5rBjn33gUGfBoKPjt2fWaAFAWZb/jufzSQSqqpJ763q9SlLX9UfBbxjUbrfDbDaT3LpcLh8DFYiaz+dot9uYTqeSW6rdd0G8Uvf7HZPJBJ7nodlsIkmSb+A7HerjUZvNBkEQCMhxHLmmaSq1fwJN0PF4RL/fR6PRgG3b8H0fw+EQRVGAu+CSLBNmQhRoPB6j1WrJiKPRCIvFAmxGl2yZXujeKPG01WqFXq+HTqeDOI4FwnpdurcCPJ/PLxhPXC6XGAwG6Ha7CMMQWZb96kRNYVokQBYcDgdEUSQGu64rPm2327cgKl4jPx4P+THZTZ7nYq45jp6rj03YDw/VppVOpxNut5v4yOdciqph0Ca+VznryZEtmz82xa71A/b7Pdbr9Ss33+v5Fx7l6ZISjAhoAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"center\"\n        title=\"center\"\n        src=\"/static/79b2744184a3ae5de4e4828bc2239a6e/533c1/simpleLogisticPlot-1.png\"\n        srcset=\"/static/79b2744184a3ae5de4e4828bc2239a6e/c26ae/simpleLogisticPlot-1.png 158w,\n/static/79b2744184a3ae5de4e4828bc2239a6e/6bdcf/simpleLogisticPlot-1.png 315w,\n/static/79b2744184a3ae5de4e4828bc2239a6e/533c1/simpleLogisticPlot-1.png 576w\"\n        sizes=\"(max-width: 576px) 100vw, 576px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n  </a>\n    </span></p>\n<p>We now turn to local logistic regression. When we fit the local logistic regression model we have to decide a <a href=\"http://en.wikipedia.org/wiki/Kernel_%28statistics%29\">kernel</a>, <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>K</mi></mrow><annotation encoding=\"application/x-tex\">K</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">K</span></span></span></span></span>, and a kernelwidth, <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>λ</mi></mrow><annotation encoding=\"application/x-tex\">\\lambda</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.69444em;vertical-align:0em;\"></span><span class=\"mord mathnormal\">λ</span></span></span></span></span>. The weight we put on each datapoint when we estimate <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>π</mi><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">\\pi(x)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">π</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">x</span><span class=\"mclose\">)</span></span></span></span></span> is a function of the distance, <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>d</mi></mrow><annotation encoding=\"application/x-tex\">d</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.69444em;vertical-align:0em;\"></span><span class=\"mord mathnormal\">d</span></span></span></span></span>, from <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>x</mi></mrow><annotation encoding=\"application/x-tex\">x</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord mathnormal\">x</span></span></span></span></span> to the datapoint.</p>\n<div class=\"math math-display\"><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mi>w</mi><mo stretchy=\"false\">(</mo><mi>d</mi><mo separator=\"true\">;</mo><mi>λ</mi><mo stretchy=\"false\">)</mo><mo>=</mo><mi>K</mi><mrow><mo fence=\"true\">(</mo><mfrac><mi>d</mi><mi>λ</mi></mfrac><mo fence=\"true\">)</mo></mrow></mrow><annotation encoding=\"application/x-tex\">w(d;\\lambda) = K\\left(\\frac{d}{\\lambda}\\right)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.02691em;\">w</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">d</span><span class=\"mpunct\">;</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathnormal\">λ</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:2.40003em;vertical-align:-0.95003em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">K</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"minner\"><span class=\"mopen delimcenter\" style=\"top:0em;\"><span class=\"delimsizing size3\">(</span></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.37144em;\"><span style=\"top:-2.314em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">λ</span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.677em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">d</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.686em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span><span class=\"mclose delimcenter\" style=\"top:0em;\"><span class=\"delimsizing size3\">)</span></span></span></span></span></span></span></div>\n<p>We will use the Epanechnikov kernel given by</p>\n<div class=\"math math-display\"><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mi>K</mi><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo><mo>=</mo><mfrac><mn>3</mn><mn>4</mn></mfrac><mrow><mo fence=\"true\">(</mo><mn>1</mn><mo>−</mo><msup><mi>x</mi><mn>2</mn></msup><mo fence=\"true\">)</mo></mrow><mn mathvariant=\"double-struck\">1</mn><mo stretchy=\"false\">(</mo><mi mathvariant=\"normal\">∣</mi><mi>x</mi><mi mathvariant=\"normal\">∣</mi><mo>&#x3C;</mo><mn>1</mn><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">K(x) = \\frac{3}{4}\\left( 1-x^2 \\right)\\mathbb{1}(|x| &#x3C; 1)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">K</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">x</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:2.00744em;vertical-align:-0.686em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.32144em;\"><span style=\"top:-2.314em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\">4</span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.677em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\">3</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.686em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"minner\"><span class=\"mopen delimcenter\" style=\"top:0em;\"><span class=\"delimsizing size1\">(</span></span><span class=\"mord\">1</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8641079999999999em;\"><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span></span></span></span></span><span class=\"mclose delimcenter\" style=\"top:0em;\"><span class=\"delimsizing size1\">)</span></span></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\">1</span><span class=\"mopen\">(</span><span class=\"mord\">∣</span><span class=\"mord mathnormal\">x</span><span class=\"mord\">∣</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">&#x3C;</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\">1</span><span class=\"mclose\">)</span></span></span></span></span></div>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 432px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/e7cba99660cf9a8a4a30be050bfb8906/0e0c3/epanechnikov-1.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 50%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAKCAYAAAC0VX7mAAAACXBIWXMAAAsTAAALEwEAmpwYAAAA3ElEQVQoz42SyQrEMAxD8/9f2WtPpfteDS+g4ClhGIOJU1uy6jhJ0vM8Os+z6vd9a9s2zfOsZVl0XVf2WOM7Z4pkxDgknNi6rhqGIZNN05Tjd51jOBIgio7jkNWSxPZ9V9/3ioZa6rEq4TiOWQVynbRDZnJOxyiF2AK+CJumUdu2pZtB/CKNIiiCUVlVSCeA7xnGWb3dDfE4pjJDElxsNIjqaipxzzJuSn5lwF4NvOu6sjJek7eDY/7eAP9lIeSVIWPgFPLdYIjJUeMmnGwBhOQQBCbpT6OpH+yXfQAC8xPzk7oVKgAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"center\"\n        title=\"center\"\n        src=\"/static/e7cba99660cf9a8a4a30be050bfb8906/0e0c3/epanechnikov-1.png\"\n        srcset=\"/static/e7cba99660cf9a8a4a30be050bfb8906/c26ae/epanechnikov-1.png 158w,\n/static/e7cba99660cf9a8a4a30be050bfb8906/6bdcf/epanechnikov-1.png 315w,\n/static/e7cba99660cf9a8a4a30be050bfb8906/0e0c3/epanechnikov-1.png 432w\"\n        sizes=\"(max-width: 432px) 100vw, 432px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n  </a>\n    </span></p>\n<p>Any kernel can be used, but it is advantagous to use a kernel, that dies off completely(i.e. puts weight 0 on some observation) as this reduces the computational cost of evaluating the model.</p>\n<p>And finally some action: We fit a local logistic regression model using <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>λ</mi><mo>=</mo><mn>200</mn></mrow><annotation encoding=\"application/x-tex\">\\lambda = 200</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.69444em;vertical-align:0em;\"></span><span class=\"mord mathnormal\">λ</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"mord\">200</span></span></span></span></span>. We chose this value of <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>λ</mi></mrow><annotation encoding=\"application/x-tex\">\\lambda</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.69444em;vertical-align:0em;\"></span><span class=\"mord mathnormal\">λ</span></span></span></span></span> using 5 repeats of 10-fold cross validation and using AUC as selection criteria. This was aided by the <code class=\"language-text\">caret</code> package and the use of custom models. The code is ugly and reflects that I’m still a novice using <code class=\"language-text\">caret</code> so I will spare you.</p>\n<div class=\"gatsby-highlight\" data-language=\"r\"><pre class=\"language-r\"><code class=\"language-r\">kernel_width <span class=\"token operator\">&lt;-</span> <span class=\"token number\">200</span>\nloclog <span class=\"token operator\">&lt;-</span> sapply<span class=\"token punctuation\">(</span>seq<span class=\"token punctuation\">(</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span><span class=\"token number\">840</span><span class=\"token punctuation\">,</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token keyword\">function</span><span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span><span class=\"token punctuation\">{</span>\n  <span class=\"token comment\"># Calculate weights and remove observations falling outside kernel</span>\n  dat <span class=\"token operator\">&lt;-</span> nhanes <span class=\"token percent-operator operator\">%>%</span> \n    filter<span class=\"token punctuation\">(</span> abs<span class=\"token punctuation\">(</span>seated <span class=\"token operator\">-</span> x<span class=\"token punctuation\">)</span> <span class=\"token operator\">&lt;</span> kernel_width<span class=\"token punctuation\">)</span> <span class=\"token percent-operator operator\">%>%</span>\n    mutate<span class=\"token punctuation\">(</span> weight <span class=\"token operator\">=</span> pmax<span class=\"token punctuation\">(</span> <span class=\"token number\">1</span> <span class=\"token operator\">-</span> <span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span>seated<span class=\"token operator\">-</span>x<span class=\"token punctuation\">)</span><span class=\"token operator\">/</span>kernel_width<span class=\"token punctuation\">)</span><span class=\"token operator\">*</span><span class=\"token operator\">*</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span><span class=\"token number\">0</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">)</span>\n  \n  <span class=\"token comment\"># Fit model locally</span>\n  lrfit <span class=\"token operator\">&lt;-</span> glm<span class=\"token punctuation\">(</span>obese <span class=\"token operator\">~</span> seated<span class=\"token punctuation\">,</span> \n               data <span class=\"token operator\">=</span> dat<span class=\"token punctuation\">,</span> \n               family <span class=\"token operator\">=</span> quasibinomial<span class=\"token punctuation\">(</span><span class=\"token string\">'logit'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> \n               weights <span class=\"token operator\">=</span> dat<span class=\"token operator\">$</span>weight <span class=\"token punctuation\">)</span>\n  \n  <span class=\"token comment\"># Predict locally</span>\n  newdata <span class=\"token operator\">&lt;-</span> data.frame<span class=\"token punctuation\">(</span> seated <span class=\"token operator\">=</span> x<span class=\"token punctuation\">)</span>\n  pred <span class=\"token operator\">&lt;-</span> predict<span class=\"token punctuation\">(</span>lrfit<span class=\"token punctuation\">,</span> newdata<span class=\"token punctuation\">,</span> type<span class=\"token operator\">=</span><span class=\"token string\">'link'</span><span class=\"token punctuation\">,</span> se.fit <span class=\"token operator\">=</span> T<span class=\"token punctuation\">)</span>\n  \n  upr <span class=\"token operator\">&lt;-</span> pred<span class=\"token operator\">$</span>fit <span class=\"token operator\">+</span> <span class=\"token punctuation\">(</span><span class=\"token number\">1.96</span> <span class=\"token operator\">*</span> pred<span class=\"token operator\">$</span>se.fit<span class=\"token punctuation\">)</span>\n  lwr <span class=\"token operator\">&lt;-</span> pred<span class=\"token operator\">$</span>fit <span class=\"token operator\">-</span> <span class=\"token punctuation\">(</span><span class=\"token number\">1.96</span> <span class=\"token operator\">*</span> pred<span class=\"token operator\">$</span>se.fit<span class=\"token punctuation\">)</span>\n  fit <span class=\"token operator\">&lt;-</span> pred<span class=\"token operator\">$</span>fit\n  \n  lrfit<span class=\"token operator\">$</span>family<span class=\"token operator\">$</span>linkinv<span class=\"token punctuation\">(</span> c<span class=\"token punctuation\">(</span>lwr<span class=\"token punctuation\">,</span> fit<span class=\"token punctuation\">,</span> upr<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n<span class=\"token punctuation\">}</span><span class=\"token punctuation\">)</span>\n\ndf <span class=\"token operator\">&lt;-</span> data.frame<span class=\"token punctuation\">(</span>seated <span class=\"token operator\">=</span> seq<span class=\"token punctuation\">(</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span><span class=\"token number\">840</span><span class=\"token punctuation\">,</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> \n                      p <span class=\"token operator\">=</span> loclog<span class=\"token punctuation\">[</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> \n                      lwr <span class=\"token operator\">=</span> loclog<span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> \n                      upr <span class=\"token operator\">=</span> loclog<span class=\"token punctuation\">[</span><span class=\"token number\">3</span><span class=\"token punctuation\">,</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> \n                      lambda <span class=\"token operator\">=</span> <span class=\"token number\">10</span><span class=\"token punctuation\">)</span> </code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"r\"><pre class=\"language-r\"><code class=\"language-r\">ggplot<span class=\"token punctuation\">(</span>df<span class=\"token punctuation\">,</span> aes<span class=\"token punctuation\">(</span>y <span class=\"token operator\">=</span> p<span class=\"token punctuation\">,</span> x <span class=\"token operator\">=</span> seated<span class=\"token punctuation\">,</span> ymin <span class=\"token operator\">=</span> lwr<span class=\"token punctuation\">,</span> ymax <span class=\"token operator\">=</span> upr<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">+</span> geom_line<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">+</span>\n  geom_ribbon<span class=\"token punctuation\">(</span>alpha <span class=\"token operator\">=</span> <span class=\"token number\">0.4</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">+</span> theme_bw<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></code></pre></div>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 576px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/29b45d4d69f0bea69b81acf6dca7a801/533c1/localLogisticPlot-1.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 62.65822784810127%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAANCAYAAACpUE5eAAAACXBIWXMAAAsTAAALEwEAmpwYAAABdklEQVQ4y41T2YrCQBDM/39IEEE88ckHEYmggoqKDx4ggsEDFe8jsZbq0KFxN7vb0JlMd09N9TFOGIZ4vV4IguBPZRyV8n6/8Xw+ZbUxDgGpdCSpxqhst1u0Wi3UajXMZrPYzguc4/GYCPgJdLlc0O12kc/nkU6nkc1mUSwWMZ1OoZkmMrRAt9sNw+EQuVwOqVRKQKrVKkqlkti4TiYTiXX0sAXiSjmdTvA8T5hQG40GFouF2Bk3n89RKBSQyWTQ7/flnEPnT6zIiKnV63WMx2Ncr1dY0UtHoxFc18VgMIgYPh6PuHNa8EqlIsp/K1oeW1ueLZfL6HQ6ESA/m80G7XZb2JA+2X2CJDWNwvo1m80I8H6/CyC7xhTX63Wc0n/GibJardDr9aIa0uD7vqTIsVBWSSB6md0fDgepZQx4Pp9FFcwWXg/9tqfu9/tosAnAHx1MrmTKZilTTgK7rPW0fruXp2dTtE/I2na7HZbL5Te/3ROMTfkCzx3hecFE1jIAAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"center\"\n        title=\"center\"\n        src=\"/static/29b45d4d69f0bea69b81acf6dca7a801/533c1/localLogisticPlot-1.png\"\n        srcset=\"/static/29b45d4d69f0bea69b81acf6dca7a801/c26ae/localLogisticPlot-1.png 158w,\n/static/29b45d4d69f0bea69b81acf6dca7a801/6bdcf/localLogisticPlot-1.png 315w,\n/static/29b45d4d69f0bea69b81acf6dca7a801/533c1/localLogisticPlot-1.png 576w\"\n        sizes=\"(max-width: 576px) 100vw, 576px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n  </a>\n    </span></p>\n<h4>Confidence intervals</h4>\n<p>You may skip the next part, as it is a bit technical. The take-home message is:\n<em>In order to obtain correct confidence intervals(CIs), multiply you kernel by a constant such that <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>K</mi><mo stretchy=\"false\">(</mo><mn>0</mn><mo stretchy=\"false\">)</mo><mo>=</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">K(0)=1</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">K</span><span class=\"mopen\">(</span><span class=\"mord\">0</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"mord\">1</span></span></span></span></span></em>.</p>\n<p>In <em>The Elements of Statistical Learning</em> there is a point about getting confidence intervals(CI) for you estimates for “free”.\nHowever in order to obtain correct CI’s you need to be careful with the weights you use.\nFor instance in logistic regression multiplying all weights by a constant factor <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>c</mi></mrow><annotation encoding=\"application/x-tex\">c</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord mathnormal\">c</span></span></span></span></span> will not influence your estimate,\nessentially you are just multiplying the log likelihood function by the same constant.\nBut the CI’s gets more narrow the higher the weights, again this is because the observed Fisher information increases with the weights.</p>\n<p>So we have to find the correct scaling <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>c</mi><mi>λ</mi></msub></mrow><annotation encoding=\"application/x-tex\">c_\\lambda</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">c</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.33610799999999996em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">λ</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span></span> for a given <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>λ</mi></mrow><annotation encoding=\"application/x-tex\">\\lambda</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.69444em;vertical-align:0em;\"></span><span class=\"mord mathnormal\">λ</span></span></span></span></span>.\nOur weights are</p>\n<div class=\"math math-display\"><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mi>w</mi><mo stretchy=\"false\">(</mo><mi>x</mi><mo separator=\"true\">;</mo><mi>λ</mi><mo stretchy=\"false\">)</mo><mo>=</mo><mi>K</mi><mrow><mo fence=\"true\">(</mo><mfrac><mi>x</mi><mi>λ</mi></mfrac><mo fence=\"true\">)</mo></mrow><msub><mi>c</mi><mi>λ</mi></msub></mrow><annotation encoding=\"application/x-tex\">w(x; \\lambda) = K\\left(\\frac{x}{\\lambda}\\right)c_\\lambda</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.02691em;\">w</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">x</span><span class=\"mpunct\">;</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathnormal\">λ</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.8359999999999999em;vertical-align:-0.686em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">K</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"minner\"><span class=\"mopen delimcenter\" style=\"top:0em;\"><span class=\"delimsizing size2\">(</span></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.10756em;\"><span style=\"top:-2.314em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">λ</span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.677em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">x</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.686em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span><span class=\"mclose delimcenter\" style=\"top:0em;\"><span class=\"delimsizing size2\">)</span></span></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">c</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.33610799999999996em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">λ</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span></span></div>\n<p>Two simple assumptions can help us find the correct weights.</p>\n<ol>\n<li>Rescaling predictors <em>and</em> <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>λ</mi></mrow><annotation encoding=\"application/x-tex\">\\lambda</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.69444em;vertical-align:0em;\"></span><span class=\"mord mathnormal\">λ</span></span></span></span></span> with a constant <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>α</mi></mrow><annotation encoding=\"application/x-tex\">\\alpha</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.0037em;\">α</span></span></span></span></span>, should leave the weights unchanged</li>\n<li>As the <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>λ</mi><mo>→</mo><mi mathvariant=\"normal\">∞</mi></mrow><annotation encoding=\"application/x-tex\">\\lambda \\rightarrow \\infty</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.69444em;vertical-align:0em;\"></span><span class=\"mord mathnormal\">λ</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">→</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord\">∞</span></span></span></span></span> we approach regular logistic regression, and thus all weights should be 1.</li>\n</ol>\n<p>In mathematical terms.</p>\n<div class=\"math math-display\"><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mi>w</mi><mo stretchy=\"false\">(</mo><mi>x</mi><mo separator=\"true\">;</mo><mi>λ</mi><mo stretchy=\"false\">)</mo><mo>=</mo><mi>w</mi><mo stretchy=\"false\">(</mo><mi>α</mi><mi>x</mi><mo separator=\"true\">;</mo><mi>α</mi><mi>λ</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">w(x; \\lambda) = w(\\alpha x; \\alpha \\lambda)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.02691em;\">w</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">x</span><span class=\"mpunct\">;</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathnormal\">λ</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.02691em;\">w</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">αx</span><span class=\"mpunct\">;</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.0037em;\">α</span><span class=\"mord mathnormal\">λ</span><span class=\"mclose\">)</span></span></span></span></span></div>\n<p>and</p>\n<div class=\"math math-display\"><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><munder><mrow><mi>lim</mi><mo>⁡</mo></mrow><mrow><mi>λ</mi><mo>→</mo><mi mathvariant=\"normal\">∞</mi></mrow></munder><mi>w</mi><mo stretchy=\"false\">(</mo><mi>x</mi><mo separator=\"true\">,</mo><mi>λ</mi><mo stretchy=\"false\">)</mo><mo>=</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">\\lim_{\\lambda \\rightarrow \\infty} w(x, \\lambda) = 1</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.5021079999999998em;vertical-align:-0.7521079999999999em;\"></span><span class=\"mop op-limits\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.69444em;\"><span style=\"top:-2.347892em;margin-left:0em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">λ</span><span class=\"mrel mtight\">→</span><span class=\"mord mtight\">∞</span></span></span></span><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span><span class=\"mop\">lim</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.7521079999999999em;\"><span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.02691em;\">w</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">x</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathnormal\">λ</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"mord\">1</span></span></span></span></span></div>\n<p>From the first equation we easily get <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>c</mi><mi>λ</mi></msub><mo>=</mo><msub><mi>c</mi><mrow><mi>α</mi><mi>λ</mi></mrow></msub><mo>=</mo><mi>c</mi></mrow><annotation encoding=\"application/x-tex\">c_\\lambda = c_{\\alpha\\lambda} =  c</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">c</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.33610799999999996em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">λ</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">c</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.33610799999999996em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.0037em;\">α</span><span class=\"mord mathnormal mtight\">λ</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord mathnormal\">c</span></span></span></span></span>, that is the constant we have to multiply the weights by, does not change with <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>λ</mi></mrow><annotation encoding=\"application/x-tex\">\\lambda</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.69444em;vertical-align:0em;\"></span><span class=\"mord mathnormal\">λ</span></span></span></span></span>. From the second equation we get</p>\n<div class=\"math math-display\"><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mtable rowspacing=\"0.2500em\" columnalign=\"right\" columnspacing=\"\"><mtr><mtd><mstyle scriptlevel=\"0\" displaystyle=\"true\"><mrow><munder><mrow><mi>lim</mi><mo>⁡</mo></mrow><mrow><mi>λ</mi><mo>→</mo><mi mathvariant=\"normal\">∞</mi></mrow></munder><mi>K</mi><mrow><mo fence=\"true\">(</mo><mfrac><mi>x</mi><mi>λ</mi></mfrac><mo fence=\"true\">)</mo></mrow><mi>c</mi><mo>=</mo><mi>K</mi><mo stretchy=\"false\">(</mo><mn>0</mn><mo stretchy=\"false\">)</mo><mi>c</mi><mo>=</mo><mn>1</mn><mtext>  </mtext><mo>⟹</mo><mtext>  </mtext><mi>c</mi><mo>=</mo><mfrac><mn>1</mn><mrow><mi>K</mi><mo stretchy=\"false\">(</mo><mn>0</mn><mo stretchy=\"false\">)</mo></mrow></mfrac><mi mathvariant=\"normal\">.</mi></mrow></mstyle></mtd></mtr></mtable><annotation encoding=\"application/x-tex\">\\begin{aligned}\n\\lim_{\\lambda \\rightarrow \\infty}K\\left(\\frac{x}{\\lambda}\\right)c = K(0)c = 1 \\implies\nc = \\frac{1}{K(0)}.\n\\end{aligned}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:2.55744em;vertical-align:-1.02872em;\"></span><span class=\"mord\"><span class=\"mtable\"><span class=\"col-align-r\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.52872em;\"><span style=\"top:-3.5287200000000003em;\"><span class=\"pstrut\" style=\"height:3.32144em;\"></span><span class=\"mord\"><span class=\"mop op-limits\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.69444em;\"><span style=\"top:-2.347892em;margin-left:0em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">λ</span><span class=\"mrel mtight\">→</span><span class=\"mord mtight\">∞</span></span></span></span><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span><span class=\"mop\">lim</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.7521079999999999em;\"><span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">K</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"minner\"><span class=\"mopen delimcenter\" style=\"top:0em;\"><span class=\"delimsizing size2\">(</span></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.10756em;\"><span style=\"top:-2.314em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">λ</span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.677em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">x</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.686em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span><span class=\"mclose delimcenter\" style=\"top:0em;\"><span class=\"delimsizing size2\">)</span></span></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathnormal\">c</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">K</span><span class=\"mopen\">(</span><span class=\"mord\">0</span><span class=\"mclose\">)</span><span class=\"mord mathnormal\">c</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mord\">1</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">⟹</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mord mathnormal\">c</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.32144em;\"><span style=\"top:-2.314em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">K</span><span class=\"mopen\">(</span><span class=\"mord\">0</span><span class=\"mclose\">)</span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.677em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.936em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span><span class=\"mord\">.</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.02872em;\"><span></span></span></span></span></span></span></span></span></span></span></span></div>\n<p>That is just multiply you kernel by a constant such the <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>K</mi><mo stretchy=\"false\">(</mo><mn>0</mn><mo stretchy=\"false\">)</mo><mo>=</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">K(0) = 1</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">K</span><span class=\"mopen\">(</span><span class=\"mord\">0</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"mord\">1</span></span></span></span></span>.</p>\n<p>Here is a plot of fit of confidence intervals for different values of <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>λ</mi></mrow><annotation encoding=\"application/x-tex\">\\lambda</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.69444em;vertical-align:0em;\"></span><span class=\"mord mathnormal\">λ</span></span></span></span></span>. Notice how the width of the confidence interval approaches that of global logistic regression for large <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>λ</mi></mrow><annotation encoding=\"application/x-tex\">\\lambda</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.69444em;vertical-align:0em;\"></span><span class=\"mord mathnormal\">λ</span></span></span></span></span>‘s.</p>\n<div class=\"gatsby-highlight\" data-language=\"r\"><pre class=\"language-r\"><code class=\"language-r\">plot_df<span class=\"token operator\">$</span>lambda <span class=\"token operator\">&lt;-</span> as.factor<span class=\"token punctuation\">(</span>plot_df<span class=\"token operator\">$</span>lambda<span class=\"token punctuation\">)</span>\nggplot<span class=\"token punctuation\">(</span>plot_df<span class=\"token punctuation\">,</span> aes<span class=\"token punctuation\">(</span>y <span class=\"token operator\">=</span> p<span class=\"token punctuation\">,</span> x <span class=\"token operator\">=</span> seated<span class=\"token punctuation\">,</span> fill <span class=\"token operator\">=</span> lambda<span class=\"token punctuation\">,</span> ymin <span class=\"token operator\">=</span> lwr<span class=\"token punctuation\">,</span> ymax <span class=\"token operator\">=</span> upr<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">+</span> geom_line<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">+</span>\n  geom_ribbon<span class=\"token punctuation\">(</span>alpha <span class=\"token operator\">=</span> <span class=\"token number\">0.4</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">+</span>\n  facet_wrap<span class=\"token punctuation\">(</span><span class=\"token operator\">~</span> lambda<span class=\"token punctuation\">)</span> <span class=\"token operator\">+</span> theme_bw<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></code></pre></div>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 576px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/8873e9ec04cb6a8c98ec8d82db984d02/533c1/CIsPlot-1.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 62.65822784810127%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAANCAYAAACpUE5eAAAACXBIWXMAAAsTAAALEwEAmpwYAAACK0lEQVQ4y2WTWY/bIBSF8///Td/70pcuUqupRm2mUWwriWM7niQTL6wG+6vAWTrqla6Aw+XA4cBCa01RFDGzNKUoS8qqogxtWbLZbNhut5TlAwu1SZrc11lrCTFNE4thGJBCoJRCOYc6n5HnM33ApERpg9YWIVr6XiDkXDtoi1Y6pnPuQRjIriP88RXx7TP6z5JxRnFWcKp+sFt9QMkztzioI5+qL/w8/4YpEsyEzhiG0xGVpegswTUNcvWCbGray4Zj+YTsay7HFa/lM63TrM5r0mbDxbR8rb4jrHqcUHUtJkuZvLvv7puW0/4Z0eV3bPKW+pSyvCRYb+946wSnQ0G+TqKqxWAtOqQx8S6DSVIKZN9jBz/3pYx31fUdxhissde7lBjreHtdU+XLqHzR9z273S46uV6v2ec55X4fsTzPSZKULMs4lHuKfR7xkGmSsityDkXJy7ngKV/DeHV5nKa7BO09J2Puzt0iP40c3ixXB2KMrccvBYdCs9kEw0YWQWIIMQykTcPX+sjHosIONjr/1g8kpeElH7h0M6HXHlNI9K+OoTa43mI7PUu2kagla1p6O5MYN3BsNNvacmwsg5sfkTMWvRWYvcS1NjwUxrDBND5c7pWiVuqdvEDaS4vzD3mhF8wIp3tfOuG9jwWR0DvHYAzBHCFEzK7r0Co4q2iaNo5vuDL6v9p3P2UcR5z3BHNuGf5mwMLOVVVR13VcFOYCFub/rZ2upgbCvyfw5v5snrwUAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"center\"\n        title=\"center\"\n        src=\"/static/8873e9ec04cb6a8c98ec8d82db984d02/533c1/CIsPlot-1.png\"\n        srcset=\"/static/8873e9ec04cb6a8c98ec8d82db984d02/c26ae/CIsPlot-1.png 158w,\n/static/8873e9ec04cb6a8c98ec8d82db984d02/6bdcf/CIsPlot-1.png 315w,\n/static/8873e9ec04cb6a8c98ec8d82db984d02/533c1/CIsPlot-1.png 576w\"\n        sizes=\"(max-width: 576px) 100vw, 576px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n  </a>\n    </span></p>\n<h4>End notes</h4>\n<p>Even if local logistic regression is not an optimal choice for a predictive model in your setting, it is still a useful tool to visualize the relationship between a predictor and a binary outcome.\nLogistic regression provides a method to control the bias, that nearest neighbor methods may exhibit near the boundaries.\nFor a more lengthy discussion see chapter 6 in <a href=\"http://statweb.stanford.edu/~tibs/ElemStatLearn/\"><em>The Elements of Statistical Learning</em></a>.</p>","frontmatter":{"title":"Locally Weighted Logistic Regression","subtitle":null,"date":"Invalid date","description":null,"image":null}},"previous":null,"next":{"fields":{"slug":"/useR-talk-2015/"},"frontmatter":{"title":"UseR! Talk"}}},"pageContext":{"id":"2bd4cf66-b30e-543e-8f5c-523b73064c5d","previousPostId":null,"nextPostId":"9154399c-d796-59cd-8450-bec7d4b210bf"}},
    "staticQueryHashes": []}